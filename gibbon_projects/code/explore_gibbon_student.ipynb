{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hApv2hxy_KO0"
   },
   "source": [
    "# Exploring Gibbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Z4bCFyUaJ1cA"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
      "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
      "Collecting en-core-web-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (67.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-sm==3.7.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.29.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (67.8.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: packaging>=20.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.10.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/ayubnur/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# ! pip install sklearn\n",
    "# ! pip install -U scikit-learn\n",
    "# ! pip install pandas\n",
    "# ! pip install spacy\n",
    "# ! python -m spacy download en\n",
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KG63QU6DIhgZ"
   },
   "source": [
    "## Pre-process text for analysis using SpaCy\n",
    "\n",
    "Before doing NLP work, most texts will need to be preprocessed in different ways. You may need to **tokenize** the text, remove stopwords, or **lemmatize** the text. What you do in pre-processing depends entirely on what your project is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "pizh0wfAQkAf"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\", disable = ['ner', 'parser'])\n",
    "nlp.max_length = 3045039"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN the second century of the Christian era, the Empire of Rome comprehended the fairest part of the earth, and the most civilised portion of mankind.\n"
     ]
    }
   ],
   "source": [
    "# open a file\n",
    "file = open(\"../text/gibbon_sample.txt\", \"r\")\n",
    "print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spaCy doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# preview spaCy doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List comprehension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular for loop to create a list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension to create a list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Gibbon\n",
    "\n",
    "For our immediate purposes we want to convert the raw text of Gibbon (which is in the form of `strings`) to a list of **lemmas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noun_and_verb_lemmas(text):\n",
    "    \"\"\"Return a list of noun and verb lemmas from a string\"\"\"\n",
    "    doc = nlp(text)\n",
    "    tokens = [token for token in doc]\n",
    "    noun_and_verb_tokens = [token for token in tokens if token.pos_ == 'NOUN' or token.pos_ == 'VERB']\n",
    "    noun_and_verb_lemmas = [noun_and_verb_token.lemma_ for noun_and_verb_token in noun_and_verb_tokens]\n",
    "    return noun_and_verb_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to memory issues with spaCy it was necessary for me to find the longest file so that I could adjust some of SpaCy's\n",
    "# default settings.\n",
    "# You do not neet to run this code.\n",
    "text_path = \"../text/gibbon_decline_and_fall/\" # path to unzipped gibbon_decline_and_fall directory\n",
    "longest = 0\n",
    "for file_name in os.listdir(text_path):\n",
    "    with open(text_path + file_name, encoding='utf-8', mode='r') as f:\n",
    "        raw_text = f.read()\n",
    "    text_len = len(raw_text)\n",
    "    if text_len > longest:\n",
    "        longest = text_len\n",
    "print(longest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes about 3 mintues\n",
    "text_path = \"../text/gibbon_decline_and_fall/\"  # path to unzipped gibbon_decline_and_fall directory\n",
    "gibbon_lemmas = {}\n",
    "for file_name in os.listdir(text_path):\n",
    "    chapter_name = file_name[23:29]\n",
    "    with open(text_path + file_name, encoding='utf-8', mode = 'r') as f:\n",
    "        raw_text = f.read()\n",
    "    lemmas = get_noun_and_verb_lemmas(raw_text)\n",
    "    gibbon_lemmas[chapter_name] = lemmas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4DhizTlQQOG"
   },
   "outputs": [],
   "source": [
    "# Attempt 2: This block of code is an alternative way to handle the memory limitations for spaCy.\n",
    "# You do not need to run this code.\n",
    "text_path = \"../text/gibbon_decline_and_fall/\"\n",
    "gibbon_lemmas = {}\n",
    "for file_name in os.listdir(text_path):\n",
    "    chapter_name = file_name[23:29]\n",
    "    with open(text_path + file_name, encoding='utf-8', mode = 'r') as f:\n",
    "        raw_text = f.read()\n",
    "    if len(raw_text) < 1000000:  # SpaCy will throw a memory error if a text is more than 1,000,000 characters\n",
    "        lemmas = get_noun_and_verb_lemmas(raw_text)\n",
    "        gibbon_lemmas[chapter_name] = lemmas\n",
    "    else:\n",
    "        print(f\"Long chapter: {chapter_name}\")\n",
    "        lemmas = []\n",
    "        text_lines = raw_text.split('\\n')\n",
    "        for text_line in text_lines:\n",
    "            line_lemmas = get_noun_and_verb_lemmas(text_line)\n",
    "            for line_lemma in line_lemmas:\n",
    "                lemmas.append(line_lemma)\n",
    "        gibbon_lemmas[chapter_name] = lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I752weTCKR-l",
    "outputId": "ebff87dd-32b7-4882-d379-27b290d47647"
   },
   "outputs": [],
   "source": [
    "# Sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code will save the data as a json file\n",
    "file_name = 'gibbon_lemmas.json'\n",
    "with open(file_name, encoding='utf-8', mode='w') as f:\n",
    "    json.dump(gibbon_lemmas, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-i5QjIaJfd-"
   },
   "source": [
    "## Find the most important words by chapter in Gibbon\n",
    "For this part we are going to use a library called [scikit-learn](https://scikit-learn.org/stable/). This library is primarily for machine learning, but many of its features are useful for DH work.\n",
    "Advanced Reading: https://towardsdatascience.com/tf-idf-explained-and-python-sklearn-implementation-b020c5e83275"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTGExuH9YyOv"
   },
   "outputs": [],
   "source": [
    "# The tool I will use here requires a string as input rather than a list, so I convert my docs from lists to strings\n",
    "gibbon_chap_strings = []\n",
    "gibbon_chap_names = []\n",
    "for key, value in gibbon_lemmas.items():\n",
    "    gibbon_chap_names.append(key)  \n",
    "    chap_string = ' '.join(value)\n",
    "    gibbon_chap_strings.append(chap_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjctTms2WWar"
   },
   "outputs": [],
   "source": [
    "# transform corpus into a matrix of word counts\n",
    "vectorizer = TfidfVectorizer(max_df=.65, min_df=1, stop_words=None, \n",
    "                             use_idf= True, norm=None)\n",
    "transformed_chaps = vectorizer.fit_transform(gibbon_chap_strings)\n",
    "transformed_chaps_as_array = transformed_chaps.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFR-PdNBWyhA"
   },
   "outputs": [],
   "source": [
    "gibbon_key_vocab_by_chap = {}\n",
    "for chap, chap_name in zip(transformed_chaps_as_array, gibbon_chap_names):\n",
    "    tf_idf_tuples = list(zip(vectorizer.get_feature_names_out(), chap))\n",
    "    sorted_tf_idf_tuples = sorted(tf_idf_tuples, key= lambda x: x[1], reverse=True)\n",
    "    k = chap_name\n",
    "    v = sorted_tf_idf_tuples[:10]  # only getting the top ten\n",
    "    gibbon_key_vocab_by_chap[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOtAg3yrN2n6",
    "outputId": "e8f042ad-2d51-4736-e23d-6b8f6a218c35"
   },
   "outputs": [],
   "source": [
    "for k, v in gibbon_key_vocab_by_chap.items():\n",
    "    result = k + ' => ' + v[0][0] + ', ' + v[1][0] + ', ' + v[2][0] + ', ' + v[3][0] + ', ' + v[4][0]\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ujc-mmSMZohr",
    "outputId": "56b3350d-d692-471b-cb0e-88ca45b6c45e"
   },
   "outputs": [],
   "source": [
    "# explore vocabulary\n",
    "gibbon_key_vocab_by_chap['chap16']  # <-- you can investigate other chapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0thCE3jvaVqp"
   },
   "source": [
    "## Conditional frequency distribution in Gibbon\n",
    "\n",
    "### Natural Language Toolkit\n",
    "The **Natural Language Toolkit** (NLTK) is a library used for natural language processing (NLP). If you want to learn more, I highly recommend working through the [NLTK Book](https://www.nltk.org/book/). This resource is a great introduction to NLP specifically and Python more generally.\n",
    "\n",
    "A **conditional frequency distribution** (cfd) is a collection of word counts for a given condition, i.e. category. Here the category is separate chapters in Gibbon. We can chart what used are used most frequently by chapter. This will tell us something about the nature of each chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cp-vlGgoMaFL",
    "outputId": "abf6549d-22ef-49bc-c588-c6e5dcc9d532"
   },
   "outputs": [],
   "source": [
    "# conditional frequency distribution\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (target, chap_name)\n",
    "    for chap_name in gibbon_lemmas.keys()\n",
    "    for lemma in gibbon_lemmas[chap_name]\n",
    "    for target in ['doctrine', 'apostle', 'presbyter', 'daemon', 'immortality']  # <-- instert token(s) to explore (lowercase)\n",
    "    if lemma.lower().startswith(target)\n",
    ")\n",
    "# display plot\n",
    "plt.figure(figsize=(20, 8))  # this expands the plot to make it more readable\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ih3TwGldGhEG"
   },
   "source": [
    "### Activity\n",
    "Based on the key vocabulary by chapter above, explore the use of different terms in the conditional frequency distribution. \n",
    "* What questions about the text does this raise for you?\n",
    "* What hypotheses about the text can you form?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "explore_gibbon.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
